{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1daca403-8700-4bd5-a466-427e757db1be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tuple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ABC, abstractmethod\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m expand, get_alpha\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mHorseshoeBayesReg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HorseshoeBayesReg\n",
      "File \u001b[0;32m~/Projects/Optimization_under_uncertainty/Experiments/Experiment_2/utils.py:116\u001b[0m\n\u001b[1;32m    112\u001b[0m             X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(([\u001b[38;5;241m1\u001b[39m], X))\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrafo_for_mvg\u001b[39m(X:np\u001b[38;5;241m.\u001b[39marray, y:\u001b[38;5;28mfloat\u001b[39m, sigma:\u001b[38;5;28mfloat\u001b[39m, Sigma_star: np\u001b[38;5;241m.\u001b[39marray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mTuple\u001b[49m[np\u001b[38;5;241m.\u001b[39marray, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    Transforms the Bayesian regression's data and parameters into the format that allow accelerated generation of multivariate Gaussian random numbers.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    (Source: Bhattacharya, Chakraborty, Mallick (2016), https://arxiv.org/pdf/1506.04778.pdf p. 4)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m            \u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sigma\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStandard deviation must be positive.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tuple' is not defined"
     ]
    }
   ],
   "source": [
    "import os, math, sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "from typing import Tuple, Optional\n",
    "import cvxpy as cvx\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import halfcauchy, invgamma\n",
    "import seaborn as sns\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from utils import expand, get_alpha\n",
    "\n",
    "from HorseshoeBayesReg import HorseshoeBayesReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453e1c31-1724-4308-89cf-224a420e1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial data\n",
    "n0        = 2500\n",
    "d         = 35\n",
    "k         = 2\n",
    "p_zero    = 0.4\n",
    "sigma_eps = 0.0\n",
    "dist = 'cauchy'\n",
    "\n",
    "# para vector\n",
    "alpha_gt = get_alpha(d, k, p_zero=0.1, dist=dist, sigma=3.)\n",
    "\n",
    "# X : design matrix\n",
    "def get_rnd_X(n:int, d:int, p:float=0.5):\n",
    "    \"\"\"\n",
    "    Generates a random design matrix with binary entries with `n` observations and `d` columns with probability `p` for an entry to be non-zero (i.e. 1).\n",
    "    \n",
    "    Args:\n",
    "       n (int)      :   Number of observations, i.e. rows in the design matrix.\n",
    "       d (int)      :   Dimension of raw input (excl. intercept, excl. interaction terms).\n",
    "       p (float)    :   Sparsity parameter, sets the probability of any given entry to be 1.\n",
    "       \n",
    "    Returns\n",
    "       X (np.array)  :  Design matrix nxd\n",
    "    \"\"\"\n",
    "    \n",
    "    p = sum([math.comb(d,i) for i in range(k+1)])\n",
    "    X = np.random.binomial(n=1, p=p, size=n*d).reshape(n,-1)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def get_rnd_Xy(alpha:np.array, n:int, d:int, k:int, sigma:float=0.0, p:float=0.5, intercept:bool=True):\n",
    "    \"\"\"\n",
    "    Generates a pair of a random design matrix and an associated vector of observations givne the groundtruth coefficient vector `alpha` and noise standard deviation `sigma`.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert 5==5, \"\"\n",
    "    \n",
    "    # raw design matrix\n",
    "    X_raw = get_rnd_X(n=n, d=d, p=p)\n",
    "    \n",
    "    # expanded X\n",
    "    X = expand(np.array(X_raw), k=k, intercept=intercept)\n",
    "    \n",
    "    # y : response\n",
    "    y = X@alpha\n",
    "\n",
    "    if(sigma>0):\n",
    "        y += np.random.normal(y)*sigma # additive noise\n",
    "        \n",
    "    return X_raw, y\n",
    "    # Bayes Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b429c-a840-4d5b-a832-b1687a6b6add",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 5\n",
    "k = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa689a-c3d7-4c16-8cc8-597d1ad8b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 0], [1, 0, 0], [1, 0, 1], [1, 1, 1], [1, 1, 1]])\n",
    "\n",
    "X\n",
    "X = X - X.mean(axis=0)\n",
    "\n",
    "\n",
    "X[:,0] = 1\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a3f67-c0f7-40d3-8462-0fb38a1ad21c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f284c9-cbb4-492f-9dcd-67810953c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "d = 5\n",
    "k = 1\n",
    "\n",
    "# instantiate\n",
    "br1 = HorseshoeBayesReg(10, 3335, 50, 1)\n",
    "\n",
    "np.random.seed(br1.seed)\n",
    "X = np.random.binomial(n=1,p=0.5,size=d*n).reshape(n,-1)\n",
    "y = np.ones(n)\n",
    "X\n",
    "\n",
    "br1.setXy(X, y, 1)\n",
    "\n",
    "\n",
    "br1.add(X[2,:], np.array([1]))\n",
    "\n",
    "br1.sample_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba498e-8e19-4998-aee5-a73fd7d35643",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc4c03-0b75-4387-97f1-9aaf21124ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mother:\n",
    "    def __init__():\n",
    "        self.b = 7\n",
    "    def ok():\n",
    "        return \"Everythign is ok\"\n",
    "    \n",
    "class test(HorseshoeBayesReg, mother):\n",
    "    def __init__(self,):\n",
    "        self.a = 5\n",
    "        \n",
    "    def get_a(self,):\n",
    "        return self.a\n",
    "    \n",
    "    def get_b(self,):\n",
    "        return self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cf65db-8aa2-4813-a304-ba415e4f57a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = test()\n",
    "\n",
    "d1.get_a()\n",
    "\n",
    "d1.get_b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf8ebf7-1799-4dd7-a762-8131565924c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d3e1ab-810d-446c-881f-2f8397d6ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cholesky_testrun():\n",
    "    # Prior\n",
    "    sigma_0 = 1.\n",
    "\n",
    "    # - tau_0, beta_0\n",
    "    rvs_half_cauchy = np.abs(np.random.standard_cauchy(size=1+p)) # Half-Cauchy <-> abs of Cauchy\n",
    "    tau_0, beta_0 = rvs_half_cauchy[0], rvs_half_cauchy[1:]\n",
    "\n",
    "    # - alpha_0\n",
    "    Sigma_0 = np.diag((beta_0**2) * sigma_0**2 * tau_0**2)\n",
    "    alpha_0 = np.random.multivariate_normal(mean=np.zeros(p), cov=Sigma_0, size=1, tol=1e-3).T[:,0]\n",
    "\n",
    "    # intermediate\n",
    "    tau_T  = tau_0\n",
    "    beta_T = beta_0\n",
    "    sigma_T = sigma_0\n",
    "    alpha_T = alpha_0\n",
    "\n",
    "    alpha_err = []\n",
    "    y_err = []\n",
    "    for i in range(100):\n",
    "        Sigma_star_inv = np.diag(1./ beta_T**2) / tau_T\n",
    "        #A_inv = np.linalg.inv((X.T @ X + np.diag(1./ beta_T**2) / tau_T))   # SLOW  2301144251.0 23011442.5     72.0% \n",
    "        \n",
    "         # Compute the matrix A = X^T @ X + diag(1 / beta_T^2) / tau_T\n",
    "        A = X.T @ X + np.diag(1. / beta_T**2) * (1. / tau_T)\n",
    "\n",
    "        # Solve the linear system A @ alpha_T = X^T @ y using Cholesky decomposition\n",
    "        L = np.linalg.cholesky(A)\n",
    "        # - mu : ...\n",
    "        mu_alpha_T = np.linalg.solve(L.T, np.linalg.solve(L, X.T @ y))\n",
    "        # - cov : Generate random samples for alpha_T using Cholesky decomposition\n",
    "        cov_matrix_chol = sigma_T**2 * np.linalg.inv(L.T) @ np.linalg.inv(L)\n",
    "        alpha_T = np.random.multivariate_normal(mean=mu_alpha_T, cov=cov_matrix_chol, size=1).T[:,0]\n",
    "    \n",
    "        N = len(X)\n",
    "        sigma_T = np.sqrt(scipy.stats.invgamma.rvs((n+p) / 2., scale=(y - X@alpha_T).T @ (y - X@alpha_T) / 2. + 0.5 * alpha_T.T @ Sigma_star_inv @ alpha_T))\n",
    "        nu_T    = scipy.stats.invgamma.rvs(1, scale=1+1./beta_T**2)\n",
    "        beta_T  = np.sqrt(scipy.stats.invgamma.rvs(1, scale=1./nu_T + alpha_T**2 / (2. * tau_T**2 * sigma_T**2)))\n",
    "        zeta_T  = scipy.stats.invgamma.rvs(1, scale=1+1./tau_T**2, size=1)\n",
    "        tau_T   = np.sqrt((p+1)/2. , 1./zeta_T + (1. / 2*sigma_T**2)*np.sum(alpha_T**2 / beta_T**2)).T\n",
    "\n",
    "        alpha_err.append(np.linalg.norm(alpha_gt-alpha_T)**2)\n",
    "        y_err.append(np.linalg.norm(X@alpha_gt-X@alpha_T)**2)\n",
    "\n",
    "\n",
    "    return alpha_err, y_err\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def Fastmvg_testrun():\n",
    "    # Prior\n",
    "    sigma_0 = 1.\n",
    "\n",
    "    # - tau_0, beta_0\n",
    "    rvs_half_cauchy = np.abs(np.random.standard_cauchy(size=1+p)) # Half-Cauchy <-> abs of Cauchy\n",
    "    tau_0, beta_0 = rvs_half_cauchy[0], rvs_half_cauchy[1:]\n",
    "\n",
    "    # - alpha_0\n",
    "    Sigma_0 = np.diag((beta_0**2) * sigma_0**2 * tau_0**2)\n",
    "    alpha_0 = np.random.multivariate_normal(mean=np.zeros(p), cov=Sigma_0, size=1, tol=1e-3).T[:,0]\n",
    "\n",
    "    # intermediate\n",
    "    tau_T  = tau_0\n",
    "    beta_T = beta_0\n",
    "    sigma_T = sigma_0\n",
    "    alpha_T = alpha_0\n",
    "    n = len(X)\n",
    "    \n",
    "    alpha_err = []\n",
    "    y_err = []\n",
    "    for i in range(50):\n",
    "        # zeta\n",
    "        zeta_T  = scipy.stats.invgamma.rvs(1, scale=1+1./tau_T**2, size=1)\n",
    "        \n",
    "        # nu \n",
    "        nu_T    = scipy.stats.invgamma.rvs(1, scale=1+1./beta_T**2)\n",
    "        \n",
    "        # tau\n",
    "        tau_T   = np.sqrt((p+1)/2. , 1./zeta_T + (1. / 2*sigma_T**2)*np.sum(alpha_T**2 / beta_T**2)).T\n",
    "        \n",
    "        # beta\n",
    "        beta_T  = np.sqrt(scipy.stats.invgamma.rvs(1, scale=1./nu_T + alpha_T**2 / (2. * tau_T**2 * sigma_T**2)))\n",
    "        \n",
    "        # Sigma star\n",
    "        Sigma_star = np.diag(beta_T**2) * tau_T\n",
    "        Sigma_star_inv = np.diag(1./ beta_T**2) / tau_T\n",
    "        \n",
    "        # coef vector\n",
    "        if(p > n and p>200):\n",
    "            alpha_T  = fast_multivariate_normal(X, y, sigma_T, Sigma_star)\n",
    "        else:\n",
    "            alpha_T  = cholesky_multivariate_normal(X, y, sigma_T, Sigma_star)\n",
    "        \n",
    "        # sigma\n",
    "        sigma_T = np.sqrt(scipy.stats.invgamma.rvs((n+p) / 2., scale=(y - X@alpha_T).T @ (y - X@alpha_T) / 2. + 0.5 * alpha_T.T @ Sigma_star_inv @ alpha_T))\n",
    "        \n",
    "        alpha_err.append(np.linalg.norm(alpha_gt-alpha_T)**2)\n",
    "        y_err.append(np.linalg.norm(X@alpha_gt-X@alpha_T)**2)\n",
    "    \n",
    "    return alpha_err, y_err, alpha_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1812ca3-9abd-4e7c-8e2a-83725e91f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha_err, y_err = Fastmvg_testrun()\n",
    "\n",
    "#alpha_err, y_err = Cholesky_testrun()\n",
    "\n",
    "#alpha_err1, y_err1 = testrun()\n",
    "#alpha_err2, y_err2 = testrun_forward()\n",
    "alpha_err3, y_err3, alpha_hat = Fastmvg_testrun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415409f-23f6-4e63-9a37-eb78d3ad6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.set_printoptions(threshold=1000)\n",
    "\n",
    "plt.hist(alpha_hat, bins=500)\n",
    "plt.title(r\"Distribution of $\\alpha_{i}$. $r(\\alpha_{i}=0)=0.0$\")\n",
    "plt.xlim(-2.5,2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7209ea-f2ca-4242-8591-c3930882a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Run Bayes Reg\n",
    "_, _, alpha_hat = Fastmvg_testrun()\n",
    "\n",
    "# dense alpha\n",
    "alpha_dense     = np.array(alpha_hat) # \n",
    "\n",
    "# sparsified alpha\n",
    "alpha_0  = np.array(alpha_hat)\n",
    "alpha_1  = np.array(alpha_hat)\n",
    "alpha_2  = np.array(alpha_hat)\n",
    "alpha_3  = np.array(alpha_hat)\n",
    "alpha_4  = np.array(alpha_hat)\n",
    "\n",
    "# sparsify\n",
    "quantile_list = [0.4, 0.75, 0.9, 0.95, 0.99]\n",
    "alpha_sparse = [None]*len(quantile_list)\n",
    "for j,p_sparse in enumerate(quantile_list):\n",
    "    alpha_sparse[j] = np.array(alpha_hat)\n",
    "    alpha_sparse[j][np.abs(alpha_hat)<np.quantile(np.abs(alpha_hat), p_sparse)]=0\n",
    "\n",
    "N_sdp = 100\n",
    "\n",
    "# DENSE SDP\n",
    "cand_dense = []\n",
    "sdp1 = SDP(d, kind='max')\n",
    "for i in range(N_sdp):\n",
    "    f_hat, x_hat = sdp1.AFO(alpha_dense)\n",
    "    #print(f'f_hat: {f_hat:.2f}, f: {x_hat @ alpha_gt:.2f}\\n\\nRegret: {-x_hat @ alpha_gt+f_hat:.2f}\\n\\n')\n",
    "    \n",
    "    cand_dense.append(x_hat @ alpha_gt)\n",
    "    \n",
    "# SPARSE SDP 0\n",
    "cand_sparse_0 = []\n",
    "sdp_0 = SDP(d, kind='max')\n",
    "for i in range(N_sdp):\n",
    "    f_hat_0, x_hat_0 = sdp_0.AFO(alpha_sparse[0])\n",
    "    cand_dense.append(x_hat_0 @ alpha_gt)\n",
    "    \n",
    "# SPARSE SDP 1\n",
    "cand_sparse_0 = []\n",
    "sdp_0 = SDP(d, kind='max')\n",
    "for i in range(N_sdp):\n",
    "    f_hat_0, x_hat_0 = sdp_0.AFO(alpha_sparse[0])\n",
    "    cand_sparse_0.append(x_hat_0 @ alpha_gt)\n",
    "    \n",
    "# SPARSE SDP 2\n",
    "cand_sparse_1 = []\n",
    "sdp_1 = SDP(d, kind='max')\n",
    "for i in range(N_sdp):\n",
    "    f_hat_1, x_hat_1 = sdp_1.AFO(alpha_sparse[1])\n",
    "    cand_sparse_1.append(x_hat_1 @ alpha_gt)\n",
    "    \n",
    "# SPARSE SDP 3\n",
    "cand_sparse_2 = []\n",
    "sdp_2 = SDP(d, kind='max')\n",
    "for i in range(N_sdp):\n",
    "    f_hat_2, x_hat_2 = sdp_2.AFO(alpha_sparse[2])\n",
    "    cand_sparse_2.append(x_hat_2 @ alpha_gt)\n",
    "    \n",
    "# SPARSE SDP 3\n",
    "cand_sparse_3 = []\n",
    "sdp_3 = SDP(d, kind='max')\n",
    "for i in range(N_sdp):\n",
    "    f_hat_3, x_hat_3 = sdp_3.AFO(alpha_sparse[3])\n",
    "    cand_sparse_3.append(x_hat_3 @ alpha_gt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7fb64d-493b-43bc-b2b3-2da9be28ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KDE plot using seaborn\n",
    "\n",
    "sns.kdeplot(data=cand_sparse_3, fill=True, color='orange', alpha=0.6, label=f'Sparse: {100. * quantile_list[3]:.0f}%')\n",
    "sns.kdeplot(data=cand_sparse_2, fill=True, color='green', alpha=0.6,  label=f'Sparse: {100. * quantile_list[2]:.0f}%')\n",
    "sns.kdeplot(data=cand_sparse_1, fill=True, color='purple', alpha=0.6, label=f'Sparse: {100. * quantile_list[1]:.0f}%')\n",
    "sns.kdeplot(data=cand_sparse_0, fill=True, color='red', alpha=0.6, label=f'Sparse: {100. * quantile_list[0]:.0f}%')\n",
    "sns.kdeplot(data=cand_dense, fill=True, color='skyblue', alpha=0.6, label='Dense')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel(r'$f \\, \\left( \\widehat{x^{*}} \\right)$')\n",
    "plt.ylabel('Density')\n",
    "plt.xlim(180,245)\n",
    "plt.suptitle(r'BOCS-SDP AFO on $\\alpha$ for varying degrees of sparsity', fontsize=13, y=0.98)\n",
    "plt.title(f'(n{0}={n0}, n=0, d={d}, k={k}, p={p}, dist=`{dist}`, p0={100.*p_zero:.0f}%)', fontsize=10)\n",
    "plt.legend()\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff",
   "language": "python",
   "name": "diff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
